# -*- coding: utf-8 -*-
"""Fingerprint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x31dQCFsyycA-Szt29X0qplhG8CJHGCi
"""

# @title Run General Fingerprint Generator
import os
import pandas as pd
import sys

# ==========================================
# 1. INSTALL DEPENDENCIES
# ==========================================
try:
    import scyjava
    from openbabel import pybel
except ImportError:
    print(" Installing dependencies... (This takes ~1 minute)")
    !apt-get update -qq > /dev/null
    !apt-get install -y openjdk-11-jdk-headless -qq > /dev/null
    !pip install -q scyjava pandas openbabel-wheel

    # Set Java Home immediately after install
    os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
    import scyjava
    from openbabel import pybel

# ==========================================
# 2. INITIALIZE CHEMISTRY TOOLS
# ==========================================
print(" Initializing CDK (Chemistry Development Kit)...")
from scyjava import config, jimport

# Add CDK to Java Classpath
config.endpoints.append('org.openscience.cdk:cdk-bundle:2.9')

# Import Java Classes
CDK = {
    'KR': jimport('org.openscience.cdk.fingerprint.KlekotaRothFingerprinter'),
    'GO': jimport('org.openscience.cdk.fingerprint.GraphOnlyFingerprinter'),
    'SUB': jimport('org.openscience.cdk.fingerprint.SubstructureFingerprinter'),
    'HYB': jimport('org.openscience.cdk.fingerprint.HybridizationFingerprinter'),
    'Parser': jimport('org.openscience.cdk.smiles.SmilesParser'),
    'Builder': jimport('org.openscience.cdk.silent.SilentChemObjectBuilder')
}

# ==========================================
# 3. DEFINE WORKER FUNCTIONS
# ==========================================
def get_smiles_column(df):
    """Auto-detects the column containing SMILES strings."""
    # 1. Try exact matches specifically for your datasets
    priority_terms = ["canonical smiles", "smiles", "canonical_smiles"]

    # Clean column names for comparison (lowercase, strip whitespace)
    cols_clean = {c.lower().strip(): c for c in df.columns}

    # Check priority terms first
    for term in priority_terms:
        # Check if the term exists strictly
        if term in cols_clean:
            return cols_clean[term]
        # Check if the term is part of a column name (e.g. "MK-Canonical SMILES")
        for clean_col, original_col in cols_clean.items():
            if term in clean_col:
                return original_col

    return None

def process_file(filepath, output_dir="output"):
    filename = os.path.basename(filepath)
    print(f"\n Processing: {filename}")

    try:
        df = pd.read_csv(filepath)
    except:
        try:
             df = pd.read_csv(filepath, encoding='latin1')
        except:
             print(f"    Error: Could not read {filename}. Is it a valid CSV?")
             return

    # Find SMILES column
    smiles_col = get_smiles_column(df)

    if not smiles_col:
        print(f"    Skipping: Could not find a 'SMILES' column in {filename}")
        print(f"   Available columns: {list(df.columns)}")
        return

    print(f"    Found SMILES column: '{smiles_col}'")

    # Prepare Tools
    fpers = {
        'KR': CDK['KR'](),
        'GRAPH': CDK['GO'](),
        'SUB': CDK['SUB'](),
        'HYB': CDK['HYB']()
    }
    sp = CDK['Parser'](CDK['Builder'].getInstance())

    results = []

    # Generate Fingerprints
    for i, row in df.iterrows():
        smiles = str(row[smiles_col])
        if pd.isna(smiles) or not smiles.strip(): continue

        data = row.to_dict()
        try:
            # OpenBabel FP2
            mol_ob = pybel.readstring("smi", smiles)
            fp2_bits = mol_ob.calcfp().bits
            data['fp2_fp'] = ''.join(['1' if x in fp2_bits else '0' for x in range(1024)])

            # CDK Fingerprints
            mol_cdk = sp.parseSmiles(smiles)
            for key, fp_obj in fpers.items():
                bits = fp_obj.getBitFingerprint(mol_cdk).asBitSet()
                data[f'{key}_fp'] = ''.join(['1' if bits.get(n) else '0' for n in range(fp_obj.getSize())])

            results.append(data)
        except:
            pass # Skip errors silently

    # Save Results
    if not results:
        print("    No valid compounds processed.")
        return

    res_df = pd.DataFrame(results)
    base_name = os.path.splitext(filename)[0]
    if not os.path.exists(output_dir): os.makedirs(output_dir)

    fp_map = {'FP2': 'fp2_fp', 'KR': 'KR_fp', 'GRAPH': 'GRAPH_fp', 'SUB': 'SUB_fp', 'HYB': 'HYB_fp'}

    saved_count = 0
    for name, col in fp_map.items():
        if col in res_df.columns:
            out_path = os.path.join(output_dir, f"{base_name}-{name}.csv")
            # Save all original cols + the one specific FP col
            cols_to_save = [c for c in res_df.columns if c not in fp_map.values()] + [col]
            res_df[cols_to_save].dropna(axis=1, how='all').to_csv(out_path, index=False)
            saved_count += 1

    print(f"    Success! Generated {saved_count} files in '/{output_dir}'")

# ==========================================
# 4. MAIN EXECUTION LOOP
# ==========================================
# Look for all CSV files in current folder
all_files = [f for f in os.listdir('.') if f.endswith('.csv')]

# Filter out files that look like outputs (contain -FP2, -KR, etc) or hidden files
inputs = [f for f in all_files if not any(x in f for x in ['-FP2', '-KR', '-GRAPH', '-SUB', '-HYB'])]

if not inputs:
    print("\n No CSV files found! Please upload a file to the Files tab.")
else:
    print(f"\n Found {len(inputs)} input file(s). Starting batch processing...")
    for csv_file in inputs:
        process_file(csv_file)